\documentclass[12pt,a4paper]{article}
\usepackage[utf8x,utf8]{inputenc}
\usepackage[toc,page]{appendix}
%\usepackage[swedish]{babel}
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{ae}
\usepackage{units}
\usepackage{url}
\usepackage{icomma}
\usepackage{listings}
\usepackage{color}
\usepackage{gauss}
\usepackage{bbm}
\usepackage{xspace}
\usepackage{float}
\usepackage{csquotes}
\newcommand{\N}{\ensuremath{\mathbbm{N}}}
\newcommand{\Z}{\ensuremath{\mathbbm{Z}}}
\newcommand{\Q}{\ensuremath{\mathbbm{Q}}}
\newcommand{\R}{\ensuremath{\mathbbm{R}}}
\newcommand{\C}{\ensuremath{\mathbbm{C}}}
\newcommand{\rd}{\ensuremath{\mathrm{d}}}
\newcommand{\id}{\ensuremath{\,\rd}}
\newcommand{\gsl}{\textsc{Gsl}\xspace}
\newcommand{\ordo}[1]{{\cal O}\left( #1 \right)}
% Want flexible vectors!
\newcommand{\myvec}[1]{\ensuremath{\mathbf{#1}}}
\usepackage{amssymb}
\usepackage{pdfpages}
\usepackage{graphicx}
\usepackage{epstopdf}
% Want beautiful tables!
\usepackage{caption}
\usepackage{dcolumn}
\setlength{\belowcaptionskip}{\baselineskip}
\newcolumntype{d}[0]{D{.}{.}{-1} }

% Special front page for Numerical Methods in Physics...
\usepackage{umuphys}            % Local umu-physics firstpage style
\author{Torbj√∏rn Ludvigsen}
\title{Fast Fourier transforms}
\course{Numerical Methods in Physics}
\email{tolu0022@student.umu.se}
\bottomtext{FNM15\#d!DNUz\#\textbackslash0}

\begin{document}
\maketitle
%\includepdf[pages={1}]{framsida.pdf}

\begin{abstract}
\end{abstract}

\vspace{2cm}
\tableofcontents
\clearpage

\section{Introduction}
This lab is about extracting binary information from a noisy amplitude modulated (AM) signal.
The signal is generated uniquely for each student and is given as a column vector
in an ASCII-encoded data-file. 

In the next section, we present some brief theory behind discrete Fourier Transforms
and how they can be of help when we want to filter out noise from a signal.
We also present a brief description of the Gauss filter that we are going to use
once the signal is transformed.

Then, in \ref{sec:code}, we present how to implement the theory as
a computer program that can be compiled and executed.
Figures and tables discussing choice of Gauss filter-bandwidth and method for automated
bit pattern recognition is included in \ref{sec:results}.

\section{Theory}
We say that the signal is a superposition of two signals; the pure signal and the noise.
The pure signal consist of a handful of frequencies, with
the most prevalent (largest amplitude) of them being a so called ``carrying frequency'',
$f_c$, and two modulating frequencies/side bands, $f_c\pm\Delta f/2$.
Together, they make the pure signal look like
a series of wave packets with equal length, that take on one of two
different amplitudes per period.

These two amplitudes are what sepparates the ``1''s in the signal from the ``0''s,
so finding the wave packets and their amplitude is the key to finding the
information hidden in the signal.

The noise is simple white noise, a signal with no particular periodicity but lots of frequencies.
The noise is as strong as the pure signal, but randomly distributed, so the wave packets
are impossible to see with the naked eye. We want to remove the noise from the signal
with a filter.

\subsection{Discrete Fourier Transform}\label{sec:ft}
The Fourier Theorem states that every periodic signal can be decomposed into
a series of sines and cosines with different frequencies and corresponding coefficients (Fourier coefficients).
Since the values of these coefficients% (the frequency distribution)
is dramatically different in our pure signal and in the noise,
we would like to do decompose our raw signal into such a series so that we can
investigate and change the coefficients.

A transformation that extracts the coefficients from a signal, $h(t)$ ``amplitude per time'',
is called a Fourier Transform. Since our signal is discrete, we use a Discrete Fourier
Transform:
\begin{equation}\label{eq:ft}
  H_n = \sum_{k=0}^{N-1} h_ke^{2\pi ikn/N},
\end{equation}
where $h_k$ is our discrete signal in time, $N$ is the number of samples we have and
$H_n$ is the amplitude of the $n$'th frequency in the signal.
Note the $i$ on the RHS that makes $H_n$ a complex valued function in general.
Note also that for purely real $h_k$, the transformed data satisfy the symmetry
\begin{equation}\label{eq:symmetry}
  H_{n-k} = H_k^*,
\end{equation}
where $^*$ means the complex conjugate.
Lastly, note that half of the frequency domain that $H_n$ is defined on
consist of negative frequencies.\footnote{Negative frequencies is a
consequence of the transform definition \eqref{eq:ft} containing complex numbers.
These negative frequences are no more
mystical than the fact that a list of recorded samples can be traversed both
forwards and backwards.}

It turns out that the inverse problem, that of extracting time dependent
amplitudes from frequency dependent amplitudes is solved with a very
similar transform, called the Inverse Fourier Transform:

\begin{equation}\label{eq:ift}
  p_k = \frac1N\sum_{i=0}^{N-1}P_ne^{-2\pi ikn/N}.
\end{equation}

The problem of removing the noise can now be expressed as:
\begin{itemize}
  \item Extract the Fourier coefficients, $H(f_n)$, of the signal with a Fourier Transform
  \item Find the coefficient that corresponds to $f_c$ and the side bands
  \item Make them dominate all other coefficients
  \item Reconstruct the (now approximately pure) signal with an Inverse Fourier Transform
\end{itemize}

Finding the carrying frequency (or equivalently its coefficient) will be
an optimization problem. We simply assume that the largest coefficient
correspond to $f_c$. If this is not the case, our simple Fourier Trasform-based
method won't work.

\subsection{The Gaussian Filter}\label{sec:gauss}
Making the coefficient of $f_c$ dominate all others is a filtering problem.
We simply multiply the found series of coefficients, $H_n$, with a function
$G(f)$ (or its discretized version $G_n = G(f_n)$) that has a maximum in $f_c$.
We denote the filtered coefficients $(GH)_n$.
Note that since \eqref{eq:ft} contains complex numbers, $H_n$ will be defined
for negative frequencies as well as positive ones, so $G$ must be mirrored
around the $y$-axis in order to scale all frequencies.\footnote{The symmetric
  property \eqref{eq:symmetry} in the frequency domain is equivalent
  to having $h(t)\in\R$ in the time domain. Failing to maintain symmetry
  after frequency-filtering makes the signal complex (and noisy) in the time domain.}

This process of multiplying all elements in a series by a function
is called filtering, and when $G(f)$ is a Gaussian curve we
call it Gaussian filtering, hence the section title.
Since the filtering is done with a frequency-dependent function, $G(f)$,
we call it frequency-filtering.

The filter function actually used in this lab is
\begin{equation}\label{eq:filter_fct}
  G(f) = e^{-\frac12\left(\frac{|f| - f_c}{\Delta f} \right)^2}
\end{equation}

Taking the Inverse Fourier Transform of a Gauss-filtered signal gives us
\begin{align}
  (g*h)_k &= \frac1N\sum_{i=0}^{N-1}G_n(\sum_{k=0}^{N-1} h_ke^{2\pi ikn/N})e^{-2\pi ikn/N}\\
          &= \frac1N\sum_{i=0}^{N-1}(GH)_ne^{-2\pi ikn/N},
\end{align}
where $(g*h)_k$ is the frequency-filtered and hopefully approximately pure version of
the signal $h_k$, and $g$ is the inverse Fourier Transform of the Gaussian $G$.

There are some details to this that are not strictly needed for understanding this
lab, but they're quite interesting anyways. 

For example, we have the notation $g*h$.
The $*$ is an operator called a convolution and its
discrete version is defined like this:
\begin{equation}\label{eq:convolution}
  (g*h)_n = \sum_{m=-\infty}^{\infty} g_m h_{(n-m)}.
\end{equation}

It is not entirely obvious from \eqref{eq:convolution}, \eqref{eq:ft} and \eqref{eq:ift} that
the three operations of Fourier Transforming, filtering and Inverse transforming is equivalent
to convolution, but this is indeed the case. This is called the Convolution Theorem, and
a proof can be found at \cite{convolution_theorem}.

Further it might not be obvious from \eqref{eq:ift} that the Inverse Fourier Transform of a
Gaussian curve is also a Gaussian curve, but this is the case for all Gaussian curves.
if we let $\mathcal{F}$ denote  a Fourier Transform we have the following relation
\[
  \mathcal{F}\left[e^{-ax^2} \right](k) = \sqrt{\frac{\pi}{a}} e^{-\pi^2k^2/a}.
\]

This suggests that we could have achieved the frequency-filtering with $G$ in just two steps,
instead of the four listed in Section \ref{sec:ft}:
\begin{itemize}
  \item Computing the Gaussian $g=\mathcal{F}^{-1}[G]$ (cheap)
  \item Computing the convolution $(g*h)_n$
\end{itemize}

\section{Code}\label{sec:code}
% describe software, abstract point of view
% describe external functions used
The code is written in C and goes through roughly the following steps:
\begin{itemize}
  \item Read data into array while counting samples
  \item Fourier transform the data
  \item Filter the data
  \item Inverse Fourier transform the data
  \item Construct bytes from data
  \item Interpret bytes as ASCII-characters
  \item Print ASCII-characters to screen
\end{itemize}

Two functions from the \Gsl library are used to do the Fourier and Inverse
Fourier transformations, namely \texttt{gsl\_fft\_complex\_radix2\_forward}
and \texttt{gsl\_fft\_complex\_radix2\_inverse}.
They don't work for data lengths that are not a power of 2,
they take complex values as input and leave the data shifted, so extra care is
taken when indexing frequency domain data.
Even though they are not the fastest Fourier transforming functions available,
they are ``simple and compact''\cite{gsl_doc}.

\subsection{Numerical methods}\label{sec:nm}
% give short overview of Cooley-Turk FFT algorithm here
% link equations in Theory to the written code
The reason for the quirks in the \texttt{gsl\_fft\_complex\_radix2\_...}
functions is that they use the (in-place) Cooley-Tukey algorithm without sorting.

The Cooley-Tukey algorithm is the classical way to implement a Fourier Transform,
since it is fairly intuitive, was discovered early\footnote{actually multiple times \cite{cooley_tukey}}
and it needs only \ordo{N\log{N}} operations (compared to $N^2$ operations needed to
compute \eqref{eq:ft} explicitly).

In fact \texttt{gsl\_fft\_complex\_radix2\_...} don't really satisfy \eqref{eq:ft} and \eqref{eq:ift}
because the in-place Cooley-Tukey without sorting shifts the indices
so that the leftmost half is swapped with the rightmost (positive frequencies
starting at $f=0$ is placed at the beginning of the array in stead of at the middle).
This shift is reversed on each application of Cooley-Tukey, so omitting explicit
sorting saves some clock cycles for us.

The filtering with \eqref{eq:filter_fct} is performed with a simple for-loop
and the constants $f_c = 1024$ and $\Delta f = 256$ found by from visually
inspecting the transformed data.

\subsection{Program}
% how to compile and use program

\section{Results}\label{sec:results}
% figures, tables, explanatory text
% answer questions posed in introduction
% make sure all issues mentioned in spec are discussed


\begin{figure}
  \begin{small}
  \centering
  \input{different_filters.tex}
  \caption{
    Visualizations of Gaussian filters with different bandwidths
    along with the the resulting signals after using them (expressed
    in absolute values).
    The frequencies are on the $x$-axis and the top left plot shows the
    the \emph{unfiltered} version of what is filtered in the three other plots.
    Notice that the highest frequencies are cut out of this plot since
    all filters zero them out anyways.
    Also note that negative frequencies not shown in this plot, they would
    look mirrored across the $y$-axis if they were included.
    We see that a bandwidth of $\unit[64]{Hz}$ lets almost only the carrying frequency
    through, and damps the modular frequencies down to amplitudes of the white
    noise. The filter with $\Delta f = \unit[128]{Hz}$ supresses a lot of noise,
    but also damps out ca $\unit[50]{\%}$ of the modular frequencies 
    (those at $\unit[896]{Hz}$ and $\unit[1152]{Hz}$).
    The filter with
    $\Delta f = \unit[256]{Hz}$ also supresses most of the noise-frequencies
    and damps the modular frequencies with only about $\unit[15]{\%}$.
    Plots of the signals after they've been filtered and transformed back
    to the time domain is found in Figure \ref{fig:different_bandwidths}.
    Since the filter is implemented programmatically, it would have been easy to
    write a filter that simply picked the information carrying frequencies.
  }
  \label{fig:different_filters}
  \end{small}
\end{figure}

\begin{figure}
  \begin{small}
  \centering
  \input{different_bandwidths.tex}
  \caption{
    The first byte of the AM-modulated binary data after transforming,
    filtering and inverse transforming. $\Delta f$ denotes the bandwidth
    the Gauss filter that has been used (see Figure \ref{fig:different_filters}).
    We see that a filter with a too narrow bandwidth, in this case $\Delta f = \unit[64]{Hz}$,
    makes overall amplitude low, and bytes look blurred/smeared out.
    A too wide bandwidth, in this case $\Delta f = \unit[512]{Hz}$ ,allows
    the noise to disturb the signal making it look somewhat irregular.
  }
  \label{fig:different_bandwidths}
  \end{small}
\end{figure}

\begin{figure}
  \begin{small}
  \centering
  \input{filtered_with_bandwidth_256.tex}
  \caption{The first tenth of the signal, filtered with a Gaussian
    filter using bandwidth
    $\Delta f = \unit[256]{Hz}$ and $f_c = \unit[1024]{Hz}$.
    Notice that time units are assumed to be such that the carrier wave
    get frequency $\unit[1024]{Hz}$ and the modulation frequency
    is $\unit[8/1024]{Hz}$.
    We se clearly the two types of
    wave packets that decode the binary information.
    The wave packets with amplitudes
    around $0.8$ can be interpreted as ``0''s
    and the ones with amplitudes around $2.4$ can be interpreted as ``1''s.
    The first eight bits in this pattern is then the binary number $01000110$.
    In decimal this is $70$ and interpreted as a
    ASCII-decoded letter, this is an \textit{F}.
  }
  \label{fig:filtered_with_bandwidth_256}
  \end{small}
\end{figure}



\section{Conclusions}
% validity of results?
% possible implications?
% possible improvements?


\clearpage
\begin{thebibliography}{99}

\bibitem{convolution_theorem}
  Wikipedia\\
  \emph{Convolution Theorem}\\
  \url{https://en.wikipedia.org/wiki/Convolution_theorem}\\
  Datum: 3 -- 2 -- 2015

\bibitem{gsl_doc}
  GNU Scientific Library\\
  \emph{Reference Manual: Radix-2 FFT routines for complex data}\\
  \url{https://www.gnu.org/software/gsl/manual/html_node/Radix_002d2-FFT-routines-for-complex-data.html}\\
  Datum: 3 -- 2 -- 2015

\bibitem{cooley_tukey}
  Wikipedia\\
  \emph{Cooley‚ÄìTukey FFT algorithm}\\
  \url{https://en.wikipedia.org/wiki/Cooley‚ÄìTukey_FFT_algorithm}
  Datum: 3 -- 2 -- 2015

%\bibitem{sampl}
%  W. H. Press, S. A. Teukolsky, W. T. Vetterling, and
%  B. P. Flannery, \emph{Numerical Recipes in C}, 2nd ed. (Cambridge
%  University Press, Cambridge, 1992).

\end{thebibliography}

\appendix
\section{Appendices}

\end{document}

%\begin{figure}
%  \begin{small}
%  \centering
%  \input{task<nr>.tex}
%  \caption{
%  }
%  \label{fig:task<nr>}
%  \end{small}
%\end{figure}

%\begin{table}
%  \begin{center}
%    \caption{<caption of a table>}
%    \label{table:task<nr>}
%    \begin{tabular}{ c | d }
%      Option      & value      \\
%      \hline
%      <option1>   & 1.2  \\
%    \end{tabular}
%  \end{center}
%\end{table}

%\begin{thebibliography}{99}
%\bibitem{octave_wiki}
%  Octave Wiki\\
%  \emph{Tips and Tricks}\\
%  \url{http://wiki.octave.org/Tips_and_tricks}\\
%  Date: 10 -- 11 -- 2014
%\end{thebibliography}
